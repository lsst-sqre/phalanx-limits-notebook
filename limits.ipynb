{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf9c030-0bcb-461e-a3de-ff3204c071c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Setup for communication with InfluxDBv2.\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "influx_url = \"https://monitoring.lsst.cloud\"\n",
    "influx_org = \"square\"\n",
    "influx_token = Path(\"./influxdb.token\").read_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272ea5cc-d8c6-4005-bfed-6d3ad1f101aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Imports for the query.\"\"\"\n",
    "\n",
    "import os\n",
    "from influxdb_client import InfluxDBClient\n",
    "from influxdb_client.client.exceptions import InfluxDBError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3983d1-ec25-4f4f-8ace-029254f41282",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryClient:\n",
    "    \"\"\"Query an InfluxDBv2 server and retrieve our monitoring data.\"\"\"\n",
    "    def __init__(self, *, url: str, token: str, org: str,\n",
    "                 templates: Path = Path(\"./templates\"),\n",
    "                 outputs: Path = Path(\"./data/query\"),\n",
    "                 duration: str = \"7d\") -> None:\n",
    "        self._client = InfluxDBClient(url=url, token=token, org=org)\n",
    "        self._mem_q = Path(templates / \"mem_query.flux\").read_text()\n",
    "        self._cpu_q = Path(templates / \"cpu_query.flux\").read_text()\n",
    "        self._outputs = outputs\n",
    "        self._applications = Path(\n",
    "            templates / \"applications\"\n",
    "        ).read_text().split()\n",
    "        self.api = self._client.query_api()\n",
    "        self._duration = duration\n",
    "        \n",
    "    def main(self) -> None:\n",
    "        \"\"\"Run the Influx query for each application and each of cpu/mem.\"\"\"\n",
    "        for app in self._applications:\n",
    "            buk = app.replace(\"-\",\"_\")\n",
    "            mem_query = self._mem_q.format(bucket=buk,duration=self._duration)\n",
    "            cpu_query = self._cpu_q.format(bucket=buk,duration=self._duration)\n",
    "\n",
    "            q_dict = { \"mem\": mem_query,\n",
    "                       \"cpu\": cpu_query }\n",
    "\n",
    "            for k in q_dict:\n",
    "                query = q_dict[k]\n",
    "                try:\n",
    "                    tables = self.api.query(query)\n",
    "                    if tables:\n",
    "                        output = tables.to_json(indent=2)\n",
    "                        if not self._outputs.is_dir():\n",
    "                            self._outputs.mkdir(parents=True)\n",
    "                        Path(\n",
    "                            self._outputs / f\"{app}-{k}.json\"\n",
    "                        ).write_text(output)\n",
    "                except InfluxDBError as exc:\n",
    "                    if exc.response.status == 404:\n",
    "                        continue\n",
    "                    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a647c30e-20c0-4e16-bf80-c1e084cdd284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query() -> None:\n",
    "    \"\"\"Execute the InfluxDBv2 query.\"\"\"\n",
    "    client = QueryClient(url=influx_url, token=influx_token, org=influx_org)\n",
    "    client.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97b6cc2-a858-4950-b9d0-cbf34a06fa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Imports for the Burster.\"\"\"\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "\n",
    "# These would have \"type\" added in front of them for Python 3.12\n",
    "Metric = list[int]\n",
    "# app/container/mtype/cluster\n",
    "PathMetric = dict[str,dict[str,dict[str,dict[str,Metric]]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3776013d-2773-4e93-a6e5-7bb26dbb4407",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Burster:\n",
    "    \"\"\"Take query data and split it into smaller files arranged for ease of analysis.\"\"\"\n",
    "    def __init__(self, *, inputs: Path = Path(\"./data/query\"),\n",
    "                 outputs: Path = Path(\"./data/burst\")\n",
    "                 ) -> None:\n",
    "        self._inp = inputs\n",
    "        self._outp = outputs\n",
    "        self._burst: PathMetric = {}\n",
    "\n",
    "    def main(self) -> None:\n",
    "        \"\"\"Burst apart and rearrange each of the input files.\"\"\"\n",
    "        for inp in self._inp.glob(\"*.json\"):\n",
    "            self.burst(inp)\n",
    "        self.write_object()\n",
    "\n",
    "    def burst(self, inp: Path) -> PathMetric:\n",
    "        \"\"\"Take the InfluxDB query data and rearrange it for ease of use.\"\"\"\n",
    "        out_obj: PathMetric = {}\n",
    "        mtype = inp.name[-8:-5]  # \"cpu\" or \"mem\"\n",
    "        app=inp.name[:-9]\n",
    "        if app not in self._burst:\n",
    "            self._burst[app] = {}\n",
    "        obj_l = json.loads(inp.read_text())\n",
    "        for obj in obj_l:\n",
    "            ctr = obj[\"container_name\"]\n",
    "            cluster = obj[\"cluster\"]\n",
    "            val = obj[\"_value\"]\n",
    "            self._add_to_burst(val, app, ctr, mtype, cluster)\n",
    "\n",
    "    def _add_to_burst(self, val: int, app: str, ctr: str, mtype: str, cluster: str) -> None:\n",
    "        \"\"\"Accumulate measurements in the right place.\"\"\"\n",
    "        if ctr not in self._burst[app]:\n",
    "            self._burst[app][ctr] = {}\n",
    "        if mtype not in self._burst[app][ctr]:\n",
    "            self._burst[app][ctr][mtype] = {}\n",
    "        if cluster not in self._burst[app][ctr][mtype]:\n",
    "            self._burst[app][ctr][mtype][cluster] = []\n",
    "        self._burst[app][ctr][mtype][cluster].append(val)\n",
    "\n",
    "    def write_object(self) -> None:\n",
    "        \"\"\"Each leaf node of the tree becomes a list of ints, each one an individual measurement.\"\"\"\n",
    "        obj = self._burst\n",
    "        for app in obj:\n",
    "            for ctr in obj[app]:\n",
    "                for mtype in obj[app][ctr]:\n",
    "                    for cluster in obj[app][ctr][mtype]:\n",
    "                        outdir = Path(self._outp / app / ctr / mtype / cluster)\n",
    "                        if not outdir.is_dir():\n",
    "                            outdir.mkdir(parents=True)\n",
    "                        outp = json.dumps(obj[app][ctr][mtype][cluster])\n",
    "                        outf = Path(outdir / \"measurements.json\")\n",
    "                        outf.write_text(outp)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993ce951-50dd-42fa-ae0a-1c114d47745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def burst() -> None:\n",
    "    \"\"\"Execute the burst.\"\"\"\n",
    "    burster = Burster()\n",
    "    burster.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efc528a-3b32-405a-9541-c576fc97bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Imports for the Summarizer.\"\"\"\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from statistics import median_low, mean\n",
    "\n",
    "from humanfriendly import format_number, format_size\n",
    "\n",
    "# Same 3.12 \"type\" advice here.\n",
    "MetricContainer = dict[str,Union[float,int,str]]\n",
    "# app/container/mtype/cluster\n",
    "Summarypath = dict[str,dict[str,dict[str, dict[str, MetricContainer]]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca8738c-4184-49b3-bb4f-4635f226f9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Summarizer:\n",
    "    \"\"\"Take the data from the burst-apart queries, summarize it, and make recommendations.\"\"\"\n",
    "    def __init__(self, *,\n",
    "                 inputs: Path = Path(\"./data/burst\"),\n",
    "                 outputs: Path = Path(\"./data/summary\"),\n",
    "                 cpu_multiplier: int = 3,\n",
    "                 mem_multiplier: int = 2\n",
    "                )-> None:\n",
    "        self._inp = inputs\n",
    "        self._outp = outputs\n",
    "        self._summary: Summarypath = {}\n",
    "        self._cpu_multiplier = cpu_multiplier\n",
    "        self._mem_multiplier = mem_multiplier\n",
    "\n",
    "    def main(self) -> None:\n",
    "        \"\"\"Make summary statistics from measurements and report them.\"\"\"\n",
    "        self.build_summary()\n",
    "        self.write_output()\n",
    "\n",
    "\n",
    "    def build_summary(self) -> None:\n",
    "        \"\"\"Make the summary statistics.\"\"\"\n",
    "        for app in self._inp.glob(\"*\"):\n",
    "            if not app.is_dir():\n",
    "                continue\n",
    "            app_n = app.name\n",
    "            for ctr in app.glob(\"*\"):\n",
    "                if not ctr.is_dir():\n",
    "                    continue\n",
    "                ctr_n = ctr.name\n",
    "                for mtype in (\"cpu\", \"mem\"):\n",
    "                    if not Path(ctr / mtype).is_dir():\n",
    "                        continue\n",
    "                    for cluster in Path(ctr / mtype).glob(\"*\"):\n",
    "                        if not cluster.is_dir():\n",
    "                            continue\n",
    "                        clus_n = cluster.name\n",
    "                        summary = self.summarize(\n",
    "                            app_n, ctr_n, mtype, clus_n\n",
    "                        )\n",
    "                        if app_n not in self._summary:\n",
    "                            self._summary[app_n] = {}\n",
    "                        if ctr_n not in self._summary[app_n]:\n",
    "                            self._summary[app_n][ctr_n] = {}\n",
    "                        if mtype not in self._summary[app_n][ctr_n]:\n",
    "                            self._summary[app_n][ctr_n][mtype] = {}\n",
    "                        if clus_n not in self._summary[app_n][ctr_n]:\n",
    "                            self._summary[app_n][ctr_n][mtype][clus_n] = {}\n",
    "\n",
    "                        # Now add human-friendly recommended fields\n",
    "                        if mtype == \"cpu\":\n",
    "                            factor = self._cpu_multiplier\n",
    "                            # If we've never seen more than 1 CPU in use,\n",
    "                            # assume it's one of our FastAPI services, and set\n",
    "                            # max to 1.\n",
    "                            #\n",
    "                            # Note that we're changing the scale from nanocores\n",
    "                            # to cores or millicores\n",
    "\n",
    "                            max_obs = summary[\"max\"]\n",
    "                            if max_obs > 1E9:\n",
    "                                summary[\"recommended_limit\"] = format_number(\n",
    "                                    float(factor * max_obs) / float(1E9)\n",
    "                                )\n",
    "                            else:\n",
    "                                summary[\"recommended_limit\"] = float(1.0)\n",
    "                            n_mcores = float(summary[\"rolling_avg\"])/float(1E6)\n",
    "                            if n_mcores > 1000:\n",
    "                                summary[\"recommended_request\"] = format_number(n_mcores/1000)\n",
    "                            else:\n",
    "                                summary[\"recommended_request\"] = f\"{format_number(n_mcores)}m\"\n",
    "                        else:\n",
    "                            factor = self._mem_multiplier\n",
    "                            summary[\"recommended_limit\"] = format_size(\n",
    "                                factor * summary[\"max\"],\n",
    "                                binary=True\n",
    "                            )                        \n",
    "                            summary[\"recommended_request\"] = format_size(\n",
    "                                summary[\"median\"],\n",
    "                                binary=True\n",
    "                            )\n",
    "                   \n",
    "                        self._summary[app_n][ctr_n][mtype][clus_n] = summary                    \n",
    "                        \n",
    "\n",
    "    def summarize(\n",
    "        self, app: str, ctr: str, mtype: str, cluster: str\n",
    "    ) -> MetricContainer:\n",
    "        \"\"\"For a given list of measurements, return \"\"\"\n",
    "        \n",
    "        def _rolling_avg(inp: list[int]) -> float:\n",
    "            \"\"\"This returns the max of the mean-taken-five-at-a-time from the input list.\"\"\"\n",
    "            accum: list[int] = []\n",
    "            if not inp:  # No data?  That's weird.\n",
    "                return 0.0\n",
    "            l_i = len(inp)\n",
    "            if l_i > 5:\n",
    "                # The normal case, where we have plenty of data.\n",
    "                for i in range(0, len(inp) - 5):\n",
    "                    sublist = inp[i:i+5]\n",
    "                    accum.append(mean(sublist))\n",
    "                return max(accum)\n",
    "            # Too short to build a rolling average?  Return the mean.\n",
    "            return mean(inp)\n",
    "        \n",
    "        holder: list[int] = []\n",
    "        meas_list = json.loads(\n",
    "            Path(\n",
    "                self._inp / app / ctr / mtype / cluster / \"measurements.json\"\n",
    "            ).read_text()\n",
    "        )\n",
    "        m_max = max(meas_list)\n",
    "        m_med = median_low(meas_list)\n",
    "        m_rolling_avg = _rolling_avg(meas_list)\n",
    "        return MetricContainer(\n",
    "            max = m_max,\n",
    "            median = m_med,\n",
    "            rolling_avg = m_rolling_avg\n",
    "        )\n",
    "            \n",
    "    def write_output(self) -> None:    \n",
    "        \"\"\"Write the summary data to a file.\"\"\"\n",
    "        if not self._outp.is_dir():\n",
    "            self._outp.mkdir(parents=True)\n",
    "        sum_j = json.dumps(self._summary, indent=2, sort_keys=True)\n",
    "        out_f = Path(self._outp / \"summary.json\")\n",
    "        out_f.write_text(sum_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56b26f1-d0d9-4f3e-9b46-c21f45af2412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize() -> None:\n",
    "    \"\"\"Execute the summary.\"\"\"\n",
    "    summarizer = Summarizer()\n",
    "    summarizer.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7487ae7c-fbb5-4ba5-840d-6780b93e4d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This lets us cache our results.  Clear the appropriate directories under data to force re-run.\"\"\"\n",
    "if not Path(\"./data/query\").is_dir():\n",
    "    query()\n",
    "if not Path(\"./data/burst\").is_dir():\n",
    "    burst()\n",
    "if not Path(\"./data/summary\").is_dir():\n",
    "    summarize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phalanx-limits",
   "language": "python",
   "name": "phalanx-limits"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
